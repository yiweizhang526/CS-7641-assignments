{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, validation_curve, learning_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import silhouette_score, homogeneity_score, completeness_score, confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_categorical_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(credit):\n",
    "\t# preprocessing - convert data type and dummy coding\n",
    "\tcols = credit.columns\n",
    "\tisCat_Index = list()\n",
    "\tfor col in cols:\n",
    "\t\tif is_string_dtype(credit[col]):\n",
    "\t\t\tcredit[col] = credit[col].astype('category')\n",
    "\t\tisCat_Index.append(is_categorical_dtype(credit[col]))\n",
    "\t\n",
    "\tcredit_d = pd.get_dummies(credit, columns=list(cols[isCat_Index]))\n",
    "\tprint(credit_d.shape)\n",
    "\treturn credit_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 62)\n"
     ]
    }
   ],
   "source": [
    "SEED = 166\n",
    "\n",
    "# preprocessing: scaling the data and split dataset\n",
    "data = pd.read_csv(\"../credit.csv\")\n",
    "data = pre_processing(data)\n",
    "predictors = data[data.columns.difference([\"default\"])]\n",
    "scaler = MinMaxScaler()\n",
    "predictors_scaled = scaler.fit_transform(predictors)\n",
    "target = data[[\"default\"]].values.ravel()\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(predictors_scaled, target, train_size=0.8, random_state=SEED, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rca = GaussianRandomProjection(n_components=34, random_state=SEED)\n",
    "rca.fit(train_X)\n",
    "train_transform = rca.transform(train_X)\n",
    "test_transform = rca.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[428. 372.]\n",
      "(800, 36)\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=SEED)\n",
    "kmeans.fit(train_transform)\n",
    "\n",
    "cluster_train = kmeans.predict(train_transform)\n",
    "cluster_test = kmeans.predict(test_transform)\n",
    "\n",
    "cluster_train = np.eye(2)[cluster_train]\n",
    "cluster_test = np.eye(2)[cluster_test]\n",
    "print(cluster_train)\n",
    "print(np.sum(cluster_train, 0))\n",
    "\n",
    "\n",
    "train_X = np.concatenate([train_transform, cluster_train], axis=1)\n",
    "test_X = np.concatenate([test_transform, cluster_test], axis=1)\n",
    "\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7262500000000001 {'batch_size': 100, 'hidden_layer_sizes': 160}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search the best parameters\n",
    "mlp_model = MLPClassifier(random_state=SEED, max_iter=1000)\n",
    "nodes = [(20), (40), (60), (80), (100), (120), (140), (160),\n",
    "         (10, 10), (20, 20), (30, 30), (40, 40), (50, 50), (60, 60), (70, 70), (80, 80), (90, 90), (100, 100),\n",
    "         (30, 10), (50, 30), (50, 10), (70, 50), (70, 30), (70, 10), (90, 70), (90, 50), (90, 30), (90, 10)]\n",
    "batch_size = [50, 100]\n",
    "\n",
    "tuned_parameters = {'hidden_layer_sizes': nodes, 'batch_size': batch_size}\n",
    "clf = GridSearchCV(mlp_model, tuned_parameters, scoring=\"accuracy\", n_jobs=-1, cv=5)\n",
    "clf.fit(train_X, train_y)\n",
    "print(clf.best_score_, clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7499999999999999 {'activation': 'logistic', 'learning_rate_init': 0.001}\n"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(batch_size=100,hidden_layer_sizes=(160), random_state=SEED, max_iter=1000)\n",
    "\n",
    "tuned_parameters = {'learning_rate_init': np.arange(0.0005, 0.01, 0.0005),\n",
    "                    'activation': [\"relu\", \"tanh\", \"logistic\"]}\n",
    "clf = GridSearchCV(mlp_model, tuned_parameters, scoring=\"accuracy\", n_jobs=-1, cv=5)\n",
    "clf.fit(train_X, train_y)\n",
    "print(clf.best_score_, clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time for final selected model is 4.015625 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7682    0.8286    0.7973       140\n",
      "           2     0.5102    0.4167    0.4587        60\n",
      "\n",
      "    accuracy                         0.7050       200\n",
      "   macro avg     0.6392    0.6226    0.6280       200\n",
      "weighted avg     0.6908    0.7050    0.6957       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mlp_model = MLPClassifier(batch_size=100,hidden_layer_sizes=(160), activation='logistic', learning_rate_init=0.001, random_state=SEED, max_iter=1000)\n",
    "\n",
    "t0_clock = time.process_time()\n",
    "mlp_model.fit(train_X, train_y)\n",
    "pred = mlp_model.predict(test_X)  # Predict with test set\n",
    "t1_clock = time.process_time()\n",
    "print(\"The training time for final selected model is \" + str(t1_clock - t0_clock) + \" seconds\")\n",
    "print(classification_report(test_y, pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
